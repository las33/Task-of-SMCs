{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from deslib.static import Oracle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sgh import SGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'datasets/'\n",
    "dataset = 'abalone'\n",
    "df = pd.read_csv(dataset_dir + dataset+'.csv', sep=',')\n",
    "df.Sex.replace({\"M\": 1, \"F\": 2, \"I\": 3}, inplace=True)\n",
    "\n",
    "df['Rings'] += -3\n",
    "df.Rings.replace({-2: 0, -1: 0}, inplace=True)\n",
    "df.Rings.replace({21: 20, 22: 20,23: 20, 24: 20,25: 20, 26: 20}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  4,  6,  7,  5, 17, 13, 16, 11,  8,  9, 15, 10,  2,  1,  3, 18,\n",
       "       14, 19,  0, 20], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rings.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEZCAYAAAB4hzlwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfMUlEQVR4nO3de7xVdZ3/8ddbVNS8gIKIXMQKNXQU9Uh216ykyEtTTlST1MOJ5jF0nZqEasZmJhpqfl2nmJEyI2+EmopZKVGo/SoRlVRABlQEAgXNS15Coc/88f2e5eawz9nrwFlnn8N5Px+P/dhrf9f6rPU5+5yzP+v7XWuvpYjAzMwMYLdmJ2BmZj2Hi4KZmRVcFMzMrOCiYGZmBRcFMzMruCiYmVnBRcF6LEk/kPTFHYz9gqRLuzqnEtsNSS9vZ977JN3U3TmZdYaLgjWdpIWSHpfUv9m5VCkiLouItzRabmeKodnOclGwppI0CngdEMCZTU2mD5C0e7NzsJ7NRcGa7Vzgd8APgEl15g+SNF/SnyTdLOmw1hmSvilpraSnJN0h6XXtbUTSmZKWSnoi90xeUTNvtaRPS7pb0pOSfiRpr5r5b5e0JMf+RtKxDX6mN0lamXs/35GkvJ4PSPp1npakr0vamLd5t6RjJE0G3gd8RtLTkq7Py78i5/1E/jmKAirpIEnX5/fhdklfbN1Onh+SpkhaCaxs9N7lobcrJV2a3/d7JB0haVrOd62khj0e651cFKzZzgUuy4/TJQ1pM/99wL8Dg4AleblWtwNjgQOBy4Eraz/MW0k6ArgC+AQwGPgpcL2kPWsW+xtgPHA4cCzwgRx7AvB94MPAQcCFwLwGQ11vB04CjsvrPb3OMm8BXg8cAQwA3g08FhGz8s/4lYjYNyLOkLQHcD1wE3Aw8FHgMklH5nV9B3gGOIRUWOsV17OBVwJj8utG790ZwCXAQOAu4EbS58Uw4N/y+2C7IBcFaxpJrwUOA+ZGxB3A/cB72yx2Q0TcEhGbgc8Br5I0AiAiLo2IxyJiS0R8FegPHMn23p3XMz8iXgD+H7A38OqaZb4VEesj4o+kD+Cxuf1DwIURcVtEbI2I2cBm4OQOfrQZEfFERKwBflWzrlovAPsBRwGKiOURsaGd9Z0M7JvX+3xE/BL4CfAeSf2AdwIXRMSzEbEMmF1nHf8REX+MiOeg1Ht3a0TcGBFbgCtJxXRGfv/mAKMkDejgPbBeykXBmmkScFNEPJpfX872e7lrWyci4mngj8ChAJI+JWl5Hn55AjiA1KNo61DgoZr1/CWvd1jNMg/XTD9L+hCGVLQ+lYdtnsjbGdGaQzvaW1chf7B/m7SX/4ikWZL2b2d9hwJrc96tHsr5DwZ2p+Z9ajNdt63Ee/dIzfRzwKMRsbXmNfV+Luv9XBSsKSTtTRpaeYOkhyU9DHwSOE7ScTWLjqiJ2Zc03LE+j4Gfn9cxMCIGAE8CqrO59aQP99b1KK/3DyVSXQtMj4gBNY99IuKKzvy89UTEtyLiROBo0jDSP7XOqpP/CEm1/68jc/6bgC3A8Jp5I9hesc5OvnfWx7goWLOcDWwljXGPzY9XALeSjjO0epuk1+bx/38HbouItaShly2kD8XdJf0L0N6e9lxggqTT8vj8p0hDQL8pked3gb+X9Mp8cPglkiZI2q+zP3AtSSflde5BOh7wZ9L7AWkv/aU1i9+Wl/mMpD0knUIa85+T995/DHxB0j6SjmLb96+ezrx31se4KFizTAIujog1EfFw64M0pPI+vXjq5OXABaRhoxNJB54hHfj8GfC/pKGUP1N/2ISIWAH8LfBfwKOkD9QzIuL5RklGxGLScYVvA48Dq8gHoXfS/qSC8zgp/8dIxzoALgLG5OGqa3OeZwJvzfnPBM6NiPvy8h8hDf88TDo4fAWp6LWn9HtnfY98kx2zXYukLwOHRES9s5DMOuSeglkvJ+koScfm4a1xwHnANc3Oy3onf7vRrPfbjzRkdCiwEfgqcF1TM7Jey8NHZmZW8PCRmZkVXBTMzKzQq48pDBo0KEaNGtXsNMzMepU77rjj0YgYXG9ery4Ko0aNYvHixc1Ow8ysV5H0UHvzPHxkZmaFyoqCpCPzNehbH09J+oSkA5Wuj78yPw+siZkmaZWkFZLqXW7YzMwqVFlRiIgVETE2IsaSLk/wLOkLNVOBBRExGliQXyNpDDCRdHGw8cDMfFlgMzPrJt01fHQacH9EPAScxYvXe59NujAauX1ORGyOiAdJ15gZ1035mZkZ3VcUJpK+cQkwpPVmIvn54Nw+jG0vyrWOba93b2ZmFau8KORLHp9JuntTh4vWadvu69aSJktaLGnxpk2buiJFMzPLuqOn8FbgzohovZPTI5KGAuTnjbl9HdveHGQ46eYi24iIWRHREhEtgwfXPc3WzMx2UHcUhffw4tARwDxevOXiJF68cNc8YKKk/pIOB0YDi7ohPzMzyyr98pqkfYA3Ax+uaZ4BzJV0HrAGOAcgIpZKmgssI90VakrNPWGtFxg19YYO56+eMaGbMjGzHVVpUYiIZ4GD2rQ9Rjobqd7y04HpVeZkZmbt8zeazcys4KJgZmYFFwUzMyu4KJiZWcFFwczMCi4KZmZWcFEwM7OCi4KZmRVcFMzMrOCiYGZmBRcFMzMruCiYmVnBRcHMzAouCmZmVqj00tlmneH7MZg1n3sKZmZWcFEwM7OCi4KZmRVcFMzMrOCiYGZmBRcFMzMrVFoUJA2QdJWk+yQtl/QqSQdKmi9pZX4eWLP8NEmrJK2QdHqVuZmZ2faq7il8E/h5RBwFHAcsB6YCCyJiNLAgv0bSGGAicDQwHpgpqV/F+ZmZWY3KioKk/YHXAxcBRMTzEfEEcBYwOy82Gzg7T58FzImIzRHxILAKGFdVfmZmtr0qewovBTYBF0u6S9L3JL0EGBIRGwDy88F5+WHA2pr4dbnNzMy6SZVFYXfgBOC/I+J44BnyUFE7VKcttltImixpsaTFmzZt6ppMzcwMqLYorAPWRcRt+fVVpCLxiKShAPl5Y83yI2rihwPr2640ImZFREtEtAwePLiy5M3M+qLKikJEPAyslXRkbjoNWAbMAybltknAdXl6HjBRUn9JhwOjgUVV5WdmZtur+iqpHwUuk7Qn8ADwQVIhmivpPGANcA5ARCyVNJdUOLYAUyJia8X5mZlZjUqLQkQsAVrqzDqtneWnA9OrzMnMzNrnbzSbmVnBRcHMzAouCmZmVnBRMDOzgu/RbAXfI9nM3FMwM7OCi4KZmRVcFMzMrOCiYGZmBRcFMzMruCiYmVnBRcHMzAouCmZmVnBRMDOzgouCmZkVXBTMzKzgomBmZgUXBTMzK7gomJlZwUXBzMwKLgpmZlaotChIWi3pHklLJC3ObQdKmi9pZX4eWLP8NEmrJK2QdHqVuZmZ2fa6o6dwakSMjYiW/HoqsCAiRgML8mskjQEmAkcD44GZkvp1Q35mZpY1Y/joLGB2np4NnF3TPiciNkfEg8AqYFwT8jMz67OqLgoB3CTpDkmTc9uQiNgAkJ8Pzu3DgLU1setym5mZdZPdK17/ayJivaSDgfmS7utgWdVpi+0WSsVlMsDIkSO7JkszMwMq7ilExPr8vBG4hjQc9IikoQD5eWNefB0woiZ8OLC+zjpnRURLRLQMHjy4yvTNzPqcyoqCpJdI2q91GngLcC8wD5iUF5sEXJen5wETJfWXdDgwGlhUVX5mZra9KoePhgDXSGrdzuUR8XNJtwNzJZ0HrAHOAYiIpZLmAsuALcCUiNhaYX5mZtZGZUUhIh4AjqvT/hhwWjsx04HpVeVku7ZRU2/ocP7qGRO6KROz3svfaDYzs4KLgpmZFVwUzMys4KJgZmYFFwUzMyu4KJiZWcFFwczMCi4KZmZWcFEwM7OCi4KZmRVcFMzMrOCiYGZmBRcFMzMrlCoKko6pOhEzM2u+sj2F/5G0SNI/SBpQaUZmZtY0pYpCRLwWeB/pdpmLJV0u6c2VZmZmZt2u9DGFiFgJfB44H3gD8C1J90n666qSMzOz7lX2mMKxkr4OLAfeCJwREa/I01+vMD8zM+tGZW/H+W3gu8BnI+K51saIWC/p85VkZmZm3a5sUXgb8FxEbAWQtBuwV0Q8GxGXVJadmZl1q7LHFH4B7F3zep/cZmZmu5CyRWGviHi69UWe3qdMoKR+ku6S9JP8+kBJ8yWtzM8Da5adJmmVpBWSTu/MD2JmZjuvbFF4RtIJrS8knQg818HytT5OOkDdaiqwICJGAwvyaySNASYCRwPjgZmS+pXchpmZdYGyReETwJWSbpV0K/Aj4CONgiQNByYA36tpPguYnadnA2fXtM+JiM0R8SCwChhXMj8zM+sCpQ40R8Ttko4CjgQE3BcRL5QI/QbwGWC/mrYhEbEhr3eDpINz+zDgdzXLrcttZmbWTcqefQRwEjAqxxwviYj4YXsLS3o7sDEi7pB0Son1q05b1FnvZGAywMiRI0us1szMyipVFCRdArwMWAJszc0BtFsUgNcAZ0p6G7AXsL+kS4FHJA3NvYShwMa8/DrSZTRaDQfWt11pRMwCZgG0tLRsVzTMzGzHle0ptABjIqL0h3BETAOmAeSewqcj4m8l/ScwCZiRn6/LIfOAyyV9DTgUGA0sKrs9MzPbeWWLwr3AIcCGLtjmDGCupPOANcA5ABGxVNJcYBmwBZjS+mU5K2fU1Bs6nL96xoRuysTMequyRWEQsEzSImBza2NEnFkmOCIWAgvz9GPAae0sNx2YXjInMzPrYmWLwheqTMLMzHqGsqek3izpMGB0RPxC0j6Av1hmZraLKXvp7A8BVwEX5qZhwLVVJWVmZs1R9hvNU0inmD4FxQ13Du4wwszMep2yRWFzRDzf+kLS7tT5YpmZmfVuZYvCzZI+C+yd7818JXB9dWmZmVkzlC0KU4FNwD3Ah4Gfku7XbGZmu5CyZx/9hXQ7zu9Wm46ZmTVT2WsfPUidYwgR8dIuz8jMzJqmM9c+arUX6dIUB3Z9OmZm1kyljilExGM1jz9ExDeAN1acm5mZdbOyw0cn1LzcjdRz2K+dxc3MrJcqO3z01ZrpLcBq4G+6PBszM2uqsmcfnVp1ImZm1nxlh4/+saP5EfG1rknHzMyaqTNnH51EujsawBnALcDaKpIyM7Pm6MxNdk6IiD8BSPoCcGVE/F1ViZmZWfcre5mLkcDzNa+fB0Z1eTZmZtZUZXsKlwCLJF1D+mbzO4AfVpaVmZk1Rdmzj6ZL+hnwutz0wYi4q7q0zMysGcoOHwHsAzwVEd8E1kk6vKKczMysScrejvMC4HxgWm7aA7i0QcxekhZJ+r2kpZL+NbcfKGm+pJX5eWBNzDRJqyStkHT6jv1IZma2o8r2FN4BnAk8AxAR62l8mYvNwBsj4jhgLDBe0smkezMsiIjRwIL8GkljgInA0cB4YKakfp37cczMbGeULQrPR0SQL58t6SWNAiJ5Or/cIz8COAuYndtnA2fn6bOAORGxOSIeBFYB40rmZ2ZmXaBsUZgr6UJggKQPAb+gxA13JPWTtATYCMyPiNuAIRGxASA/H5wXH8a2X4Zbl9vMzKybNDz7SJKAHwFHAU8BRwL/EhHzG8VGxFZgrKQBwDWSjuloU/VWUSefycBkgJEjRzZKwczMOqFhUYiIkHRtRJwINCwE7azjCUkLSccKHpE0NCI2SBpK6kVA6hmMqAkbDqyvs65ZwCyAlpaW7YqGmZntuLLDR7+TdFJnVixpcO4hIGlv4E3AfaTrJ03Ki00CrsvT84CJkvrn011HA4s6s00zM9s5Zb/RfCrw95JWk85AEqkTcWwHMUOB2fkMot2AuRHxE0m/JR2jOA9YQ7q1JxGxVNJcYBnpng1T8vCTmZl1kw6LgqSREbEGeGtnVxwRdwPH12l/DDitnZjpwPTObsvMzLpGo57CtaSroz4k6eqIeGd3JGVmZs3R6JhC7RlBL60yETMza75GRSHamTYzs11Qo+Gj4yQ9Reox7J2n4cUDzftXmp2ZmXWrDotCRPjaQ2ZmfUjZU1LNdnmjpt7Q4fzVMyZ0UyZmzdOZ+ymYmdkuzj2FHsR7qmbWbO4pmJlZwUXBzMwKLgpmZlZwUTAzs4KLgpmZFVwUzMys4KJgZmYFFwUzMyu4KJiZWcFFwczMCi4KZmZWcFEwM7OCi4KZmRVcFMzMrFBZUZA0QtKvJC2XtFTSx3P7gZLmS1qZnwfWxEyTtErSCkmnV5WbmZnVV2VPYQvwqYh4BXAyMEXSGGAqsCAiRgML8mvyvInA0cB4YKYk3w7UzKwbVXaTnYjYAGzI03+StBwYBpwFnJIXmw0sBM7P7XMiYjPwoKRVwDjgt1XlaNaVfJMk2xV0yzEFSaOA44HbgCG5YLQWjoPzYsOAtTVh63Jb23VNlrRY0uJNmzZVmbaZWZ9TeVGQtC9wNfCJiHiqo0XrtMV2DRGzIqIlIloGDx7cVWmamRkVFwVJe5AKwmUR8ePc/IikoXn+UGBjbl8HjKgJHw6srzI/MzPbVpVnHwm4CFgeEV+rmTUPmJSnJwHX1bRPlNRf0uHAaGBRVfmZmdn2KjvQDLwGeD9wj6Qlue2zwAxgrqTzgDXAOQARsVTSXGAZ6cylKRGxtcL8zMysjSrPPvo19Y8TAJzWTsx0YHpVOZmZWcf8jWYzMyu4KJiZWcFFwczMCi4KZmZWcFEwM7OCi4KZmRVcFMzMrOCiYGZmBRcFMzMruCiYmVnBRcHMzAouCmZmVnBRMDOzgouCmZkVXBTMzKzgomBmZoUq77xmZp0wauoNHc5fPWNCN2VifZl7CmZmVnBRMDOzgoePupC7/2bW27mnYGZmhcqKgqTvS9oo6d6atgMlzZe0Mj8PrJk3TdIqSSsknV5VXmZm1r4qewo/AMa3aZsKLIiI0cCC/BpJY4CJwNE5ZqakfhXmZmZmdVR2TCEibpE0qk3zWcApeXo2sBA4P7fPiYjNwIOSVgHjgN9WlZ/ZrsbHtKwrdPcxhSERsQEgPx+c24cBa2uWW5fbtiNpsqTFkhZv2rSp0mTNzPqannKgWXXaot6CETErIloiomXw4MEVp2Vm1rd0d1F4RNJQgPy8MbevA0bULDccWN/NuZmZ9XndXRTmAZPy9CTgupr2iZL6SzocGA0s6ubczMz6vMoONEu6gnRQeZCkdcAFwAxgrqTzgDXAOQARsVTSXGAZsAWYEhFbq8rNzMzqq/Lso/e0M+u0dpafDkyvKh8zM2uspxxoNjOzHsBFwczMCi4KZmZWcFEwM7OCL51tZoAvk2GJewpmZlZwUTAzs4KHj2q4+2y24zr6//H/Tu/hnoKZmRVcFMzMrOCiYGZmBR9TMLOm8/G8nsM9BTMzK7gomJlZwcNHZtbrefip67inYGZmBfcUzKzPc0/jRe4pmJlZwUXBzMwKu9TwkbuAZtYXdeVn3y5VFMzMmmFX2iHtccNHksZLWiFplaSpzc7HzKwv6VE9BUn9gO8AbwbWAbdLmhcRy5qbmZlZdXpST6On9RTGAasi4oGIeB6YA5zV5JzMzPoMRUSzcyhIehcwPiL+Lr9+P/DKiPhIzTKTgcn55ZHAig5WOQh4dCdScrzjHd/7tu34xvGHRcTgejN61PARoDpt21StiJgFzCq1MmlxRLTscDKOd7zjdyi+N+fe1+N72vDROmBEzevhwPom5WJm1uf0tKJwOzBa0uGS9gQmAvOanJOZWZ/Ro4aPImKLpI8ANwL9gO9HxNKdWGWpYSbHO97xXR7fm3Pv0/E96kCzmZk1V08bPjIzsyZyUTAzs4KLgpmZFXrUgeadJeko0jegh5G+37AemBcRy7tx+8OA2yLi6Zr28RHx8xLx44CIiNsljQHGA/dFxE93MJ8fRsS5Oxj7WtI3zO+NiJtKLP9KYHlEPCVpb2AqcAKwDPhSRDzZIP5jwDURsXYHcm09U219RPxC0nuBVwPLgVkR8UKJdbwMeAfplOgtwErgikZ5m+1qdpkDzZLOB95DujTGutw8nPRhMSciZuzEuj8YERc3WOZjwBTSB9FY4OMRcV2ed2dEnNAg/gLgraRCPR94JbAQeBNwY0RMbxDf9tRdAacCvwSIiDMbxC+KiHF5+kP5Z7kGeAtwfaP3T9JS4Lh8Btks4FngKuC03P7XDeKfBJ4B7geuAK6MiE0dxdTEXkZ63/YBngD2BX6ct62ImNQg/mPAGcDNwNuAJcDjpCLxDxGxsEweti1JB0fExiZu/6CIeKxZ2+8ukg4ApgFnA63fUt4IXAfMiIgnOrXCiNglHsD/AnvUad8TWLmT615TYpl7gH3z9ChgMakwANxVMr4f6YPtKWD/3L43cHeJ+DuBS4FTgDfk5w15+g0l4u+qmb4dGJynXwLcUyJ+eW0ubeYtKbN90nDmW4CLgE3Az4FJwH4NYu/Oz7sDjwD98muVfO/uqYnZB1iYp0eW+d3lZQ8AZgD3AY/lx/LcNmAn//5+VmKZ/YH/AC4B3ttm3swS8YcA/026IOVBwBfy+zIXGFoi/sA2j4OA1cBA4MAS8ePbvJcXAXcDlwNDSsTPAAbl6RbgAWAV8FCjv//8v/N54GU7+PtpAX6V//9GkHbqnsz/R8eXiN8X+DdgaY7bBPwO+EDJ7d8InA8c0ub3eT4wv7M/z650TOEvwKF12ofmeR2SdHc7j3uAISW23y/ykFFErCZ9KL9V0teof/mOtrZExNaIeBa4PyKeyut6rkz+pD/MO4DPAU9G2rt9LiJujoibS8TvJmmgpINIe9eb8vafIQ2nNHKvpA/m6d9LagGQdATQcPgmbSr+EhE3RcR5pN/lTNIQ2gMlct8T2I/0oX5Abu8P7FFi2/DiUGr/vB4iYk0n4ueSehenRMRBEXEQqaf2OHBlo2BJJ7TzOJHU82zkYtLf2dXARElXS+qf551cIv4HpKG+taQPuOeACcCtwP+UiH+U9PfX+lhMGkq9M0838qWa6a+SdmjOIH2wXlgifkJEtF7r5z+Bd0fEy0lXXP5qg9iBwADgV5IWSfqkpHqfJe2ZCXwFuAH4DXBhRBxAGkKdWSL+MtLf+OnAvwLfAt4PnCrpSx0FZqMi4ssR8XBrQ0Q8HBFfJu3YdM6OVMae+CB9eKwCfkb64sYs0p7mKmr2QjqIf4T0z3dYm8co0lh1o/hfAmPbtO0O/BDYWiL+NmCfPL1bTfsBtNnzbrCe4aQPoW9ToodTE7ea9If5YH4+JF7ciymzp38A6YPl/vyzvJDXczNp+KhRfLt75MDeDWI/mbf1EPAxYAHwXdKe7gUltv1x0l7pLNKe/gdz+2DglpLv34odmVezzNb8N/SrOo/nSsQvafP6c8D/J+2xN/z7Ydue4pqO1t1O/Kfz/9tf1bQ92Im/vzvb217J7d8H7J6nf9dmXoc93Tbbfh3pg/zh/N5P3sn3rswowe/bvL49P+9GOqbYKP4m4DPU9KhIO7LnA78o+zsoYjsb0JMf+U08GXgn8K483a9k7EXAa9uZd3mJ+OHUdN/azHtNifj+7bQPqv1H68R7MYF0gHdn39N9gMM7sfx+wHHAiZTo9tfEHbGTeR4KHJqnB+Tf/7hOxB+dY47awe3v1D8mcC8wup15a0vEL6dmZyK3TSINSTxUIv73NdNfbDOv4fBhXq51h+Rr+e/ggU68f+uAfwQ+RSrwqplXZgjwo/l38EbS0Nc3gNeT9rwvaRC7XdEkDeWOBy4use3fkoY9zyHtmJyd298ALC4R/5vWzx5S7+jGmnlldigGAl8mFcbHgT/mv4cvU2Lobrv1dTbADz/82P7R5h/zj23+MQeWiH8XcGQ7884uEf8V4E112sdT4pgaaUx73zrtLweu6uR7cQZpTPzhTsRc0ObRekzrEOCHJddxCvAj0vGpe4Cfki6zv3uDuDk7+bs/jjSu/zPgKOCbpBMelgKvLhF/LLAox/yavINE6ql+rGQOR5FOStm3TXvDUZLt1rUzb4YffvjR+EEejupL8aQTJI7prfn3hG2XjScNma4AriUNA59VM6/00HPrY5c5JdWsp5K0JiI6f8DP8U2P7w2555NhXhURT0saRToV/JKI+KakuyLi+M5sc5f68ppZs0i6u71ZlDh7zfHNi+/NuWfbnPko6RTgKkmHUe7Mx224KJh1jSGkUwofb9Mu0oFEx/fc+N6cO8DDksZGxBKA3GN4O/B94K9KxG/DRcGsa/yEdJBvSdsZkhY6vkfH9+bcAc6lzXeJImILcK6kMt/x2HabPqZgZmatdqVvNJuZ2U5yUTAzs4KLgllJkg6RNEfS/ZKWSfqppCMk3dvs3My6ig80m5UgSaRLic+OiIm5bSzlThk06zXcUzAr51TghYgorhiazxYpbgokaZSkWyXdmR+vzu1DJd0iaYmkeyW9TlI/ST/Ir++R9Mnu/5HMtueeglk5x5AuCd2RjcCbI+LPkkaTbhbUAryXfKMkSa33zBgLDIuIYwAkDagudbPyXBTMus4ewLfzsNJW4IjcfjvwfUl7ANdGxBJJDwAvlfRfpOvwN7zlqVl38PCRWTlLSZcD78gnSfflOI7UQ9gTICJuIV3G+Q/AJZLOjYjH83ILSbc+/V41aZt1jouCWTm/BPrn+1cDIOkk0o2YWh0AbIiIv5DunNUvL3cYsDEivku6b8cJkgaR7n9wNfDPQIf38DbrLh4+MishIkLSO4BvSJoK/Jl0meJP1Cw2E7ha0jmku3Y9k9tPAf5J0gvA06TLEgwDLpbUumM2rfIfwqwEX+bCzMwKHj4yM7OCi4KZmRVcFMzMrOCiYGZmBRcFMzMruCiYmVnBRcHMzAouCmZmVvg/cM7o++a+UUEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(df['Rings'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Abalone histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df['Rings']\n",
    "X = df.drop(labels=['Rings'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle_for_random_subspace(meta_model, X_test, y_test):\n",
    "    base_models = meta_model.estimators_\n",
    "    base_models_feats = meta_model.estimators_features_\n",
    "\n",
    "    base_models_preds = []\n",
    "    for i in range(len(base_models)):\n",
    "        X_test_subspace = X_test.iloc[:,base_models_feats[i]] #selecting only the columns used for the ith base model.\n",
    "        y_pred = base_models[i].predict(X_test_subspace)\n",
    "        base_models_preds.append(y_pred)\n",
    "\n",
    "    oracle_hits = []\n",
    "    for i in range(len(y_test)):\n",
    "        oracle_hit = 0\n",
    "        for j in range(len(base_models_preds)):\n",
    "            if base_models_preds[j][i] == y_test[i]:\n",
    "                oracle_hit = 1\n",
    "                break\n",
    "        oracle_hits.append(oracle_hit)\n",
    "\n",
    "    oracle_score = np.sum(oracle_hits)/len(oracle_hits)\n",
    "    #print('Oracle score = ', oracle_score)\n",
    "    return oracle_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import random\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "class dumb_base:\n",
    "    classe: int   \n",
    "        \n",
    "    def __init__(self, value):\n",
    "        self.classe = value\n",
    "        \n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        saida = []\n",
    "        for index in range(len(X_test)):\n",
    "            saida.append(self.classe)\n",
    "        \n",
    "        return saida\n",
    "\n",
    "\n",
    "class clf_base_r:\n",
    "    clf_1: Perceptron\n",
    "    clf_2: Perceptron\n",
    "    h: KMeans   \n",
    "        \n",
    "    def __init__(self):\n",
    "        self.clf_1 = Perceptron()\n",
    "        self.clf_2 = Perceptron()\n",
    "        self.h = KMeans\n",
    "        \n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        saida = []\n",
    "        for index, row in X_test.iterrows():\n",
    "            dim = self.h.predict([row])[0]\n",
    "            #print('kmeasn dim',dim)\n",
    "            if(dim == 0):\n",
    "                saida.append(self.clf_1.predict([row])[0])\n",
    "            else:\n",
    "                saida.append(self.clf_2.predict([row])[0])\n",
    "        \n",
    "        return saida\n",
    "        \n",
    "    def fit(self,X_train, y_train):\n",
    "        \n",
    "        self.h = KMeans(n_clusters=2, n_init=1, max_iter=1).fit(X_train)\n",
    "         \n",
    "        k_selection = self.h.predict(X_train)\n",
    "        \n",
    "        base1 =  []\n",
    "        y1 = []\n",
    "        \n",
    "        base2 =  []\n",
    "        y2 = []\n",
    "                \n",
    "        for index, d1 in enumerate(k_selection):\n",
    "            if(d1 == 0):\n",
    "                base1.append(X_train.iloc[index])\n",
    "                y1.append(y_train[index])\n",
    "            else:\n",
    "                base2.append(X_train.iloc[index])\n",
    "                y2.append(y_train[index])                \n",
    "        \n",
    "        base1 = pd.DataFrame(base1,columns=X_train.columns)\n",
    "        base2 = pd.DataFrame(base2,columns=X_train.columns)\n",
    "        if len(Counter(y1).keys()) >1:\n",
    "            self.clf_1.fit(base1,y1)\n",
    "        else:\n",
    "             self.clf_1 = dumb_base(y1[0])\n",
    "        if len(Counter(y2).keys()) >1:\n",
    "            self.clf_2.fit(base2,y2)\n",
    "        else:\n",
    "             self.clf_2 = dumb_base(y2[0])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "class random_linear_oracle:\n",
    "    n_: int\n",
    "    pool_classifiers: []\n",
    "        \n",
    "        \n",
    "    def __init__(self, n_value=10):\n",
    "        self.n_ = n_value\n",
    "        self.pool_classifiers = []\n",
    "        \n",
    "        for x in range(self.n_):            \n",
    "            self.pool_classifiers.append(clf_base_r())\n",
    "    \n",
    "    def fit(self,X_train, y_train):\n",
    "        for x in range(self.n_): \n",
    "            self.pool_classifiers[x] = self.pool_classifiers[x].fit(X_train, y_train)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        saidas = []\n",
    "        for x in range(self.n_): \n",
    "            saidas.append(self.pool_classifiers[x].predict(X_test))                \n",
    "        \n",
    "        saidas_clfs = [list(x) for x in zip(*saidas)]\n",
    "        saida = []\n",
    "        for v in saidas_clfs:\n",
    "            occurence_count = Counter(v) \n",
    "            saida.append(occurence_count.most_common(1)[0][0])\n",
    "        \n",
    "\n",
    "        return saida\n",
    "    \n",
    "    def oracle(self,X_test, y_test):\n",
    "        saidas = []\n",
    "        for x in range(self.n_): \n",
    "            saidas.append(self.pool_classifiers[x].predict(X_test))                \n",
    "        \n",
    "        saidas_clfs = [list(x) for x in zip(*saidas)]\n",
    "        hits = 0\n",
    "        for index, v in enumerate(saidas_clfs):\n",
    "             if(y_test[index] in v):\n",
    "                hits = hits + 1\n",
    "        \n",
    "\n",
    "        return hits/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    n_estimators_list = [10,20,40,60,80,100]\n",
    "    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "    for qtd_estimators in  n_estimators_list:\n",
    "        print(qtd_estimators)\n",
    "        bagging_oracle  = []\n",
    "        adaboost_oracle = []\n",
    "        randomsubspace_oracle = [] \n",
    "        randomlinearoracle_oracle = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X,y):\n",
    "\n",
    "            pool_bagging  = BaggingClassifier(base_estimator=Perceptron(),n_estimators=qtd_estimators, random_state=42)\n",
    "            pool_adaboost  = AdaBoostClassifier(base_estimator=Perceptron(),n_estimators=qtd_estimators, algorithm='SAMME', random_state=42)\n",
    "            pool_randomsubspace  = BaggingClassifier(base_estimator=Perceptron(),n_estimators=qtd_estimators,max_features=0.5,bootstrap=False, random_state=42)\n",
    "            pool_random_oracle = random_linear_oracle(n_value=qtd_estimators)\n",
    "\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            pool_bagging.fit(X_train,y_train)\n",
    "            pool_adaboost.fit(X_train,y_train)\n",
    "            pool_randomsubspace.fit(X_train,y_train) \n",
    "            pool_random_oracle.fit(X_train, y_train.values)\n",
    "\n",
    "\n",
    "            oracle_bagging = Oracle(pool_bagging).fit(X_train, y_train)           \n",
    "            bagging_oracle.append(oracle_bagging.score(X_test,y_test.values))\n",
    "\n",
    "\n",
    "            oracle_adaboost = Oracle(pool_adaboost).fit(X_train, y_train)         \n",
    "            adaboost_oracle.append(oracle_adaboost.score(X_test,y_test.values))\n",
    "\n",
    "            randomsubspace_oracle.append(oracle_for_random_subspace(pool_randomsubspace, X_test, y_test.values))\n",
    "\n",
    "            randomlinearoracle_oracle.append(pool_random_oracle.oracle(X_test, y_test.values))\n",
    "\n",
    "\n",
    "\n",
    "        models_score = [bagging_oracle,adaboost_oracle,randomsubspace_oracle, randomlinearoracle_oracle]\n",
    "\n",
    "        algoritmos = {'model': ['bagging_oracle','adaboost_oracle','randomsubspace_oracle','randomlinearoracle_oracle'],\n",
    "            'mean': np.mean(models_score, axis=1),\n",
    "            'std': np.std(models_score, axis=1)\n",
    "            }\n",
    "\n",
    "        df = pd.DataFrame(algoritmos, columns = ['model', 'mean', 'std'])\n",
    "\n",
    "\n",
    "        #print(df)\n",
    "        df.to_csv(dataset +'_model_score_'+str(qtd_estimators)+'_estimators', index=False) \n",
    "#run_experiment()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erros_count_class(y_predict,y_test):\n",
    "    classes_count = [0] * len(set(y_test))  \n",
    "    \n",
    "    for index, y in enumerate(y_predict):\n",
    "        if(y != y_test[index]):\n",
    "            classes_count[y_test[index]] += 1\n",
    "\n",
    "    return classes_count\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "sgh_oracle  = []\n",
    "hyperplanes_count = [] \n",
    "erros_count = []\n",
    "\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    pool_sgh = SGH()\n",
    "    pool_sgh.fit(X_train.values,y_train.values)    \n",
    "    oracle_sgh = Oracle(pool_sgh).fit(X_train, y_train) \n",
    "    \n",
    "    sgh_oracle.append(oracle_sgh.score(X_test,y_test.values))\n",
    "    hyperplanes_count.append(pool_sgh.hyperplanes)\n",
    "    erros_count.append(erros_count_class(oracle_sgh.predict(X_test,y_test.values),y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_oracle: 0.9968873735782025\n",
      "std_oracle: 0.001221435554315956\n",
      "mean erros_count: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.4 0.  0.  0.2 0.6 0.  0.  0.2\n",
      " 0.2 0.2 0.4]\n",
      "std erros_count: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.48989795 0.8        0.\n",
      " 0.         0.4        0.8        0.         0.         0.4\n",
      " 0.4        0.4        0.8       ]\n",
      "hyperplanes mean [2.2 3.2 2.8 3.2 3.8 4.4 5.  4.6 5.  5.  4.8 4.8 4.6 4.6 4.  3.6 4.2 3.2\n",
      " 3.  3.2 2.8]\n",
      "hyperplanes std [0.4        0.9797959  0.74833148 0.9797959  0.74833148 0.48989795\n",
      " 1.26491106 0.48989795 0.63245553 0.63245553 0.74833148 0.74833148\n",
      " 0.48989795 0.48989795 0.63245553 0.48989795 0.4        0.4\n",
      " 0.         0.4        0.4       ]\n"
     ]
    }
   ],
   "source": [
    "print(\"mean_oracle:\", np.mean(sgh_oracle ))\n",
    "print(\"std_oracle:\", np.std(sgh_oracle ))\n",
    "\n",
    "print(\"mean erros_count:\", np.mean(erros_count, axis=0))\n",
    "print(\"std erros_count:\", np.std(erros_count, axis=0))\n",
    "\n",
    "print(\"hyperplanes mean\", np.mean(hyperplanes_count, axis=0))\n",
    "print(\"hyperplanes std\", np.std(hyperplanes_count, axis=0))    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
