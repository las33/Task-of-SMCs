{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from deslib.static import Oracle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sgh import SGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'datasets/'\n",
    "df = pd.read_csv(dataset_dir + 'epileptic_seizure.csv', sep=',')\n",
    "df.columns.values[0] = \"Intance_name\"\n",
    "df['y'] += -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(df['y'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Epileptic seizure dataset histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "y = df['y']\n",
    "X = df.drop(labels=['y','Intance_name'], axis=1)\n",
    "X = pd.DataFrame(ss.fit_transform(X),columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle_for_random_subspace(meta_model, X_test, y_test):\n",
    "    base_models = meta_model.estimators_\n",
    "    base_models_feats = meta_model.estimators_features_\n",
    "\n",
    "    base_models_preds = []\n",
    "    for i in range(len(base_models)):\n",
    "        X_test_subspace = X_test.iloc[:,base_models_feats[i]] #selecting only the columns used for the ith base model.\n",
    "        y_pred = base_models[i].predict(X_test_subspace)\n",
    "        base_models_preds.append(y_pred)\n",
    "\n",
    "    oracle_hits = []\n",
    "    for i in range(len(y_test)):\n",
    "        oracle_hit = 0\n",
    "        for j in range(len(base_models_preds)):\n",
    "            if base_models_preds[j][i] == y_test[i]:\n",
    "                oracle_hit = 1\n",
    "                break\n",
    "        oracle_hits.append(oracle_hit)\n",
    "\n",
    "    oracle_score = np.sum(oracle_hits)/len(oracle_hits)\n",
    "    #print('Oracle score = ', oracle_score)\n",
    "    return oracle_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import random\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "class dumb_base:\n",
    "    classe: int   \n",
    "        \n",
    "    def __init__(self, value):\n",
    "        self.classe = value\n",
    "        \n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        saida = []\n",
    "        for index in range(len(X_test)):\n",
    "            saida.append(self.classe)\n",
    "        \n",
    "        return saida\n",
    "\n",
    "\n",
    "class clf_base_r:\n",
    "    clf_1: Perceptron\n",
    "    clf_2: Perceptron\n",
    "    h: KMeans   \n",
    "        \n",
    "    def __init__(self):\n",
    "        self.clf_1 = Perceptron()\n",
    "        self.clf_2 = Perceptron()\n",
    "        self.h = KMeans\n",
    "        \n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        saida = []\n",
    "        for index, row in X_test.iterrows():\n",
    "            dim = self.h.predict([row])[0]\n",
    "            #print('kmeasn dim',dim)\n",
    "            if(dim == 0):\n",
    "                saida.append(self.clf_1.predict([row])[0])\n",
    "            else:\n",
    "                saida.append(self.clf_2.predict([row])[0])\n",
    "        \n",
    "        return saida\n",
    "        \n",
    "    def fit(self,X_train, y_train):\n",
    "        \n",
    "        self.h = KMeans(n_clusters=2, n_init=1, max_iter=1).fit(X_train)\n",
    "         \n",
    "        k_selection = self.h.predict(X_train)\n",
    "        \n",
    "        base1 =  []\n",
    "        y1 = []\n",
    "        \n",
    "        base2 =  []\n",
    "        y2 = []\n",
    "                \n",
    "        for index, d1 in enumerate(k_selection):\n",
    "            if(d1 == 0):\n",
    "                base1.append(X_train.iloc[index])\n",
    "                y1.append(y_train[index])\n",
    "            else:\n",
    "                base2.append(X_train.iloc[index])\n",
    "                y2.append(y_train[index])                \n",
    "        \n",
    "        base1 = pd.DataFrame(base1,columns=X_train.columns)\n",
    "        base2 = pd.DataFrame(base2,columns=X_train.columns)\n",
    "        if len(Counter(y1).keys()) >1:\n",
    "            self.clf_1.fit(base1,y1)\n",
    "        else:\n",
    "             self.clf_1 = dumb_base(y1[0])\n",
    "        if len(Counter(y2).keys()) >1:\n",
    "            self.clf_2.fit(base2,y2)\n",
    "        else:\n",
    "             self.clf_2 = dumb_base(y2[0])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "class random_linear_oracle:\n",
    "    n_: int\n",
    "    pool_classifiers: []\n",
    "        \n",
    "        \n",
    "    def __init__(self, n_value=10):\n",
    "        self.n_ = n_value\n",
    "        self.pool_classifiers = []\n",
    "        \n",
    "        for x in range(self.n_):            \n",
    "            self.pool_classifiers.append(clf_base_r())\n",
    "    \n",
    "    def fit(self,X_train, y_train):\n",
    "        for x in range(self.n_): \n",
    "            self.pool_classifiers[x] = self.pool_classifiers[x].fit(X_train, y_train)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        saidas = []\n",
    "        for x in range(self.n_): \n",
    "            saidas.append(self.pool_classifiers[x].predict(X_test))                \n",
    "        \n",
    "        saidas_clfs = [list(x) for x in zip(*saidas)]\n",
    "        saida = []\n",
    "        for v in saidas_clfs:\n",
    "            occurence_count = Counter(v) \n",
    "            saida.append(occurence_count.most_common(1)[0][0])\n",
    "        \n",
    "\n",
    "        return saida\n",
    "    \n",
    "    def oracle(self,X_test, y_test):\n",
    "        saidas = []\n",
    "        for x in range(self.n_): \n",
    "            saidas.append(self.pool_classifiers[x].predict(X_test))                \n",
    "        \n",
    "        saidas_clfs = [list(x) for x in zip(*saidas)]\n",
    "        hits = 0;\n",
    "        for index, v in enumerate(saidas_clfs):\n",
    "             if(y_test[index] in v):\n",
    "                hits = hits + 1\n",
    "        \n",
    "\n",
    "        return hits/len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    n_estimators_list = [10,20,40,60,80,100]\n",
    "    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "    for qtd_estimators in  n_estimators_list:\n",
    "        print(qtd_estimators)\n",
    "        bagging_oracle  = []\n",
    "        adaboost_oracle = []\n",
    "        randomsubspace_oracle = [] \n",
    "        randomlinearoracle_oracle = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X,y):\n",
    "\n",
    "            pool_bagging  = BaggingClassifier(base_estimator=Perceptron(),n_estimators=qtd_estimators, random_state=42)\n",
    "            pool_adaboost  = AdaBoostClassifier(base_estimator=CalibratedClassifierCV(Perceptron()),n_estimators=qtd_estimators,  random_state=42)\n",
    "            pool_randomsubspace  = BaggingClassifier(base_estimator=Perceptron(),n_estimators=qtd_estimators,max_features=0.5,bootstrap=False, random_state=42)\n",
    "            pool_random_oracle = random_linear_oracle(n_value=qtd_estimators)\n",
    "\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            pool_bagging.fit(X_train,y_train)\n",
    "            pool_adaboost.fit(X_train,y_train)\n",
    "            pool_randomsubspace.fit(X_train,y_train) \n",
    "            pool_random_oracle.fit(X_train, y_train.values)\n",
    "\n",
    "\n",
    "            oracle_bagging = Oracle(pool_bagging).fit(X_train, y_train)           \n",
    "            bagging_oracle.append(oracle_bagging.score(X_test,y_test.values))\n",
    "\n",
    "\n",
    "            oracle_adaboost = Oracle(pool_adaboost).fit(X_train, y_train)         \n",
    "            adaboost_oracle.append(oracle_adaboost.score(X_test,y_test.values))\n",
    "\n",
    "            randomsubspace_oracle.append(oracle_for_random_subspace(pool_randomsubspace, X_test, y_test.values))\n",
    "\n",
    "            randomlinearoracle_oracle.append(pool_random_oracle.oracle(X_test, y_test.values))\n",
    "\n",
    "\n",
    "\n",
    "        models_score = [bagging_oracle,adaboost_oracle,randomsubspace_oracle, randomlinearoracle_oracle]\n",
    "\n",
    "        algoritmos = {'model': ['bagging_oracle','adaboost_oracle','randomsubspace_oracle','randomlinearoracle_oracle'],\n",
    "            'mean': np.mean(models_score, axis=1),\n",
    "            'std': np.std(models_score, axis=1)\n",
    "            }\n",
    "\n",
    "        df = pd.DataFrame(algoritmos, columns = ['model', 'mean', 'std'])\n",
    "\n",
    "\n",
    "        #print(df)\n",
    "        df.to_csv('model_score_'+str(qtd_estimators)+'_estimators', index=False)  \n",
    "#run_experiment()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erros_count_class(y_predict,y_test):\n",
    "    classes_count = [0] * len(set(y_test))  \n",
    "    \n",
    "    for index, y in enumerate(y_predict):\n",
    "        if(y != y_test[index]):\n",
    "            classes_count[y_test[index]] += 1\n",
    "\n",
    "    return classes_count\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "sgh_oracle  = []\n",
    "hyperplanes_count = [] \n",
    "erros_count = []\n",
    "\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    pool_sgh = SGH()\n",
    "    pool_sgh.fit(X_train.values,y_train.values)    \n",
    "    oracle_sgh = Oracle(pool_sgh).fit(X_train, y_train) \n",
    "    \n",
    "    sgh_oracle.append(oracle_sgh.score(X_test,y_test.values))\n",
    "    hyperplanes_count.append(pool_sgh.hyperplanes)\n",
    "    erros_count.append(erros_count_class(oracle_sgh.predict(X_test,y_test.values),y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_oracle: 0.998695652173913\n",
      "std_oracle: 0.0006735623210795382\n",
      "mean erros_count: [1.  0.  0.8 0.8 0.4]\n",
      "std erros_count: [1.09544512 0.         1.16619038 0.74833148 0.48989795]\n",
      "hyperplanes mean [6.6 5.2 6.2 5.2 4. ]\n",
      "hyperplanes std [1.0198039  1.46969385 2.03960781 0.74833148 0.89442719]\n"
     ]
    }
   ],
   "source": [
    "print(\"mean_oracle:\", np.mean(sgh_oracle ))\n",
    "print(\"std_oracle:\", np.std(sgh_oracle ))\n",
    "\n",
    "print(\"mean erros_count:\", np.mean(erros_count, axis=0))\n",
    "print(\"std erros_count:\", np.std(erros_count, axis=0))\n",
    "\n",
    "print(\"hyperplanes mean\", np.mean(hyperplanes_count, axis=0))\n",
    "print(\"hyperplanes std\", np.std(hyperplanes_count, axis=0)) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
